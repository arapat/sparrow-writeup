\section{Introduction}\label{sec:intro}

A major bottleneck for machine learning from big data is the movement
of data between storage units. This includes disk, memory and cache
organization and communication between different computers.
In this work we describe two new ways to reduce this I/O bottleneck
and accelerate learning in the context of boosting trees.

Many machine learning algorithms, including XGBoost~\cite and
lightGBM~\cite{}, follow a similar pattern. At each iteration the
complete training set is scanned. Then, based on statistics calculated
from the training set, the model is updated to decrease the loss.

Scanning all of the data is obviously optimal from the point of view
of the statistical estimates. However, the incremental improvemen in
the model, given an increase from a fracton of the data to the full
data, might be small. If it is sufficiently small, then stopping early
and proceeding to the next iteration can result in significantly
faster running time.

This idea was introduced by Wald\cite{wald_sequential_1973} in the
1940s under the title ``Sequential analysis'' (SA). We describe SA
precisely in Section~\ref{sec:sequential-analysis}. 


As an illustrative
example, suppose that our goal is to find a classifier from
$M_1,\ldots,M_k$ whose error rate is close to the minimum across that
$k$ models. The standard approach is to scan all of the traininqg
examples, compute the average error of each model, and choose the
model with the minimal error. The SA approach is to read the examples
one by one, each time updating the error estimate for each model, and
emply a specifically designed {\em stopping rule} to decide when to
stop and which model to output. An example where SA will stop much
before the standard approach is when one rule has an error rate of
$0.1$ while all of the other rules have error of $0.5$.
Using stopping rules to accelerate boosting has been studied before 
by Domingo and Watanabe~\cite{domingo_scaling_2000} and
by Bradley and Schapire~\cite{bradley_filterboost:_2007}.

The first contribution of this paper is a new protocol for
parallelizing boosting algorithms, based on stopping rules, which we
call ``tell me something new'' or \tmsn. Most parallelized algorithms,
including Spark-ML, XGBoost and LightGBM use
Bulk-Synchronization~\ref{valiant_bridging_1990} (BS). On the other
hand, \tmsn\ is an asynchronous protocol with a weak notion of common state.

We now describe \tmsn\ in the context of boosting.
The main computation step of any boosting algorithm is the search for
a weak rule that is slightly better than random guessing. Usually, the
stated goal is to find the {\em best} weak rule. However, for adaboost
to make progress, {\em any} rule whose error is significantly smaller
than $1/2$ can be used. This relaxation of the requirement makes it
possible to use stopping rules.

As the standard goal of boosting algorithms is to find the {\em best
weak rule} most implementation of boosting algorithms {\em scan all
of the training data} at each iteration, which becomes very slow
when the data is large. As mentioned
above~\cite{domingo_scaling_2000,bradley_filterboost:_2007} proposed
to use early stopping in the non-parallelized context. The i
Data paralel and feature paralel
implementations of boosting~\cite{} accelerate this computation, but
still require reading each training point.  \tmsn\ parallelization is
a variant of feature parallelism. As in bulk-synchronous
feature-parallel boosting, each \tmsn\ worker scans locally stored
training examples to evaluate the error of a set of weak
rules. However {\em unlike} bulk-synchronized, only a (typically
small) fraction of the data is scanned.  The workers all use a
stopping rule to decide when to terminate the search. The stopping
rule fires when it identifies a weak rule whose error is (with high
probability) smaller than $1/2-\gamma$. When this good weak rule has
been identified, it interrupts the search, adds the found rule to the
strong rule, and broadcasts this strong rule. The other workers, upon
recieving the new strong rule, interrupt their own search and use the
new rule.

This rough version of \tmsn\ would work if the workers were
synchronized and communication was instantanous. Both are unrealistic
assumptions. To remove the need for these assumptions we add a {\em
  global measure of progress}, which is an upper bound on the expected
loss of the strong hypothesis. When a worker broadcasts a new strong
rule, it pairs it with this upper bound. When a worker recieves a
strong rule, it acccepts it only if the newcomers upper bound is
smaller than the current upper bound. The full details are in
section~\ref{sec:}

We call this protocol ``tell me something new'' because the workers
send out information only when they have ``something new'' which in
our case means a significantly better strong rule. This protocol has
several desirable properties:

Both XGBoost and LightGBM 
Bulk-Synchronization~\ref{valiant_bridging_1990} model of parallel
computation. In this model the workers are all synchronized at the
start of each boosting iteration. This establishes a well defined {\em
  common state} at the synchronization boundary which simplifies the
reasoning about the algorithm an it's interaction with the hardware
and the OS.

The main contribution of this p``tell me something new'' or
\tmsn\ {\em we do away with both synchronization and common state}.

\begin{enumerate}
\item {\bf No head-node} Most distributed systems rely on a head-node
  that synchronizes the workers. The head node is a
  single-point-of-failure and a bottleneck, especially systems with a
  large number of workers. \tmsn\ avoids these problems because it
  does not require a head-node.
\item {\bf Reduced communication bandwidth:} In typical bulk-synchronous
  protocols all workers send and recieve information from the head
  node at each step. This can mean a lot of communication even when
  there is little progress in terms of reducing loss. The workers in
  \tmsn\ remain mute when as long as they don't find anything useful.
\item {\bf No blocking} The communication operations are all
  non-blocking, in other words, at no point does a worker wait for a
  response from another worker. This means that CPU utilzation is not
  reduce by wait times.
\item {\bf Robustness} As a result of the fact that there is no
  synchronization and no head node, they system is very robust. If a
  single computer is slow or crashes, the effect on the other
  computers is small. Computers can be removed or added at any time
  and will quickly catch up to the current best model and start
  contributing their cycles to the search.
\end{enumerate}

The second contribution of this paper is a method to improve the usage
of main memory when training examples have non-uniform
weights. Intuitively, when a large fraction of the examples have very
low weight, they contribute little to the error estimates. We show how
to quantify the effect of non-uniform weights in general and show how
selective sampling can increase the accuracy of the estimates. We also
propose a stopping rule when learning from non-uniform weights.

The rest of the paper is organized as follows.

The rest of the paper is divided into four sections.
First we give a general description of \tmsn\ in Section~\ref{sec:tmsn}.
Then we introduce a special application of our algorithm, namely \Sparrow, in Section~\ref{sec:boost}.
After that we describe in more details of the algorithms and the system design of \Sparrow\ in
Section~\ref{sec:Algorithms}.
Finally, we present empirical results in Section~\ref{sec:experiments}.

